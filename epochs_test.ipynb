{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建VAE模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense,Layer,Input,Lambda\n",
    "from keras.layers import Input, Concatenate, Add\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import manifold\n",
    "from scipy.stats import wasserstein_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算欧氏距离\n",
    "# def dist(x,y):\n",
    "#     return np.sqrt(np.sum(np.square(x-y)))\n",
    "\n",
    "\n",
    "# # 按欧式距离计算精确度\n",
    "# def calAccuracy_Euc(latent_x,latent_c,class_num = 3):\n",
    "#     predict_list = []\n",
    "# #     latent_x = latent_x.tolist()\n",
    "# #     latent_c = latent_c.tolist()\n",
    "    \n",
    "#     if class_num == 3:\n",
    "#         for i in range(6000): \n",
    "#             distance_list = [dist(latent_x[i], latent_c[0]),\n",
    "#                              dist(latent_x[i], latent_c[1]),\n",
    "#                              dist(latent_x[i], latent_c[2])]\n",
    "#             min_index = distance_list.index(min(distance_list))\n",
    "#             predict_list.append(min_index)\n",
    "        \n",
    "# #         print(predict_list)\n",
    "\n",
    "#         count = 0\n",
    "#         for i in range(0,2000):\n",
    "#             if predict_list[i]==0:\n",
    "#                 count=count+1\n",
    "#         for i in range(2000,4000):\n",
    "#             if predict_list[i]==1:\n",
    "#                 count=count+1\n",
    "#         for i in range(4000,6000):\n",
    "#             if predict_list[i]==2:\n",
    "#                 count=count+1\n",
    "\n",
    "#         return count\n",
    "    \n",
    "#     if class_num == 4:\n",
    "#         for i in range(8000):\n",
    "#             distance_list = [dist(latent_x[i], latent_c[0]),\n",
    "#                              dist(latent_x[i], latent_c[1]),\n",
    "#                              dist(latent_x[i], latent_c[2]),\n",
    "#                              dist(latent_x[i], latent_c[3])]\n",
    "#             min_index = distance_list.index(min(distance_list))\n",
    "#             predict_list.append(min_index)\n",
    "        \n",
    "# #         print(predict_list)\n",
    "\n",
    "#         count = 0\n",
    "#         for i in range(0,2000):\n",
    "#             if predict_list[i]==0:\n",
    "#                 count=count+1\n",
    "#         for i in range(2000,4000):\n",
    "#             if predict_list[i]==1:\n",
    "#                 count=count+1\n",
    "#         for i in range(4000,6000):\n",
    "#             if predict_list[i]==2:\n",
    "#                 count=count+1\n",
    "#         for i in range(6000,8000):\n",
    "#             if predict_list[i]==3:\n",
    "#                 count=count+1\n",
    "#         return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算余弦距离\n",
    "# def dist(vector_a, vector_b):\n",
    "#     \"\"\"\n",
    "#     计算两个向量之间的余弦相似度\n",
    "#     :param vector_a: 向量 a \n",
    "#     :param vector_b: 向量 b\n",
    "#     :return: sim\n",
    "#     \"\"\"\n",
    "#     vector_a = np.mat(vector_a)\n",
    "#     vector_b = np.mat(vector_b)\n",
    "#     num = float(vector_a * vector_b.T)\n",
    "#     denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "#     cos = num / denom\n",
    "#     sim = 0.5 + 0.5 * cos\n",
    "#     return sim\n",
    "\n",
    "# 曼哈顿距离\n",
    "def dist(x,y):\n",
    "    return np.sum(np.abs(x - y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 按欧式距离计算精确度\n",
    "def calAccuracy_Euc(samples_num,latent_x,latent_c,class_num = 3):\n",
    "    predict_list = []\n",
    "#     latent_x = latent_x.tolist()\n",
    "#     latent_c = latent_c.tolist()\n",
    "    \n",
    "    if class_num == 3:\n",
    "        for i in range(samples_num*3): \n",
    "            distance_list = [dist(latent_x[i], latent_c[0]),\n",
    "                             dist(latent_x[i], latent_c[1]),\n",
    "                             dist(latent_x[i], latent_c[2])]\n",
    "            min_index = distance_list.index(min(distance_list))\n",
    "            predict_list.append(min_index)\n",
    "        \n",
    "#         print(predict_list)\n",
    "\n",
    "        count = 0\n",
    "        for i in range(0,samples_num):\n",
    "            if predict_list[i]==0:\n",
    "                count=count+1\n",
    "        for i in range(samples_num,samples_num*2):\n",
    "            if predict_list[i]==1:\n",
    "                count=count+1\n",
    "        for i in range(samples_num*2,samples_num*3):\n",
    "            if predict_list[i]==2:\n",
    "                count=count+1\n",
    "\n",
    "        return count\n",
    "    \n",
    "    if class_num == 4:\n",
    "        for i in range(samples_num*4):\n",
    "            distance_list = [dist(latent_x[i], latent_c[0]),\n",
    "                             dist(latent_x[i], latent_c[1]),\n",
    "                             dist(latent_x[i], latent_c[2]),\n",
    "                             dist(latent_x[i], latent_c[3])]\n",
    "            min_index = distance_list.index(min(distance_list))\n",
    "            predict_list.append(min_index)\n",
    "        \n",
    "#         print(predict_list)\n",
    "\n",
    "        count = 0\n",
    "        for i in range(0,samples_num):\n",
    "            if predict_list[i]==0:\n",
    "                count=count+1\n",
    "        for i in range(samples_num,samples_num*2):\n",
    "            if predict_list[i]==1:\n",
    "                count=count+1\n",
    "        for i in range(samples_num*2,samples_num*3):\n",
    "            if predict_list[i]==2:\n",
    "                count=count+1\n",
    "        for i in range(samples_num*3,samples_num*4):\n",
    "            if predict_list[i]==3:\n",
    "                count=count+1\n",
    "        return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集视觉特征\n",
    "x_train_img = np.load(r\".\\data\\train\\x_train_2048.npy\")\n",
    "y_train_oh = np.load(r\".\\data\\train\\y_train_oh.npy\")\n",
    "# 测试集视觉特征\n",
    "x_test_img = np.load(r\".\\data\\test\\x_test_2048.npy\")\n",
    "y_test_oh = np.load(r\".\\data\\test\\y_test_oh.npy\")\n",
    "# 训练集语义特征\n",
    "aux_data_train = np.load(r\"./data/aux_data/aux_data_train_lsk.npy\")\n",
    "# 测试集语义特征\n",
    "aux_data_test = np.load(r\"./data/aux_data/aux_data_test_lsk.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_num = 2000\n",
    "#处理训练集\n",
    "x_train_IF = x_train_img[0:samples_num]\n",
    "x_train_OF = x_train_img[2000:2000+samples_num]\n",
    "x_train_BF = x_train_img[4000:4000+samples_num]\n",
    "x_train_img = np.concatenate((x_train_IF,x_train_OF,x_train_BF))\n",
    "#处理语义\n",
    "semantic_IF = aux_data_train[0:samples_num]\n",
    "semantic_OF = aux_data_train[2000:2000+samples_num]\n",
    "semantic_BF = aux_data_train[4000:4000+samples_num]\n",
    "aux_data_train = np.concatenate((semantic_IF,semantic_OF,semantic_BF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 2048)\n",
      "(6000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_img.shape)\n",
    "print(aux_data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# IF = [[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]]*2000\n",
    "# OF = [[0,0,0,0,0,1,0,0,0,0,0,1,1,0,1,0]]*2000\n",
    "# BF = [[0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1]]*2000\n",
    "# IO = [[1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,0]]*2000\n",
    "# IB = [[1,1,1,0,0,0,0,1,0,0,0,1,1,0,1,1]]*2000\n",
    "# OB = [[0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0]]*2000\n",
    "# IOB =[[1,1,1,1,1,1,0,1,1,0,1,0,0,0,1,1]]*2000\n",
    "\n",
    "# aux_data_train = IF + OF +BF\n",
    "# aux_data_test = IO + IB + OB + IOB\n",
    "\n",
    "# aux_data_train = np.array(aux_data_train)\n",
    "# print(aux_data_train.shape)\n",
    "\n",
    "# aux_data_test = np.array(aux_data_test)\n",
    "# print(aux_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda\\envs\\tensorflow-115\\lib\\site-packages\\tensorflow_core\\python\\ops\\losses\\losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "train loss 5.2970185\n",
      "train accuracy is 66.67%\n",
      "accuracy is 25.00%\n",
      "accuracy is 33.33%\n",
      "train loss 1.1756802\n",
      "train accuracy is 79.98%\n",
      "accuracy is 35.50%\n",
      "accuracy is 47.80%\n",
      "train loss 0.46964008\n",
      "train accuracy is 86.85%\n",
      "accuracy is 44.15%\n",
      "accuracy is 60.38%\n",
      "train loss 0.29214755\n",
      "train accuracy is 92.68%\n",
      "accuracy is 42.96%\n",
      "accuracy is 59.22%\n",
      "train loss 0.22190183\n",
      "train accuracy is 94.58%\n",
      "accuracy is 49.61%\n",
      "accuracy is 69.87%\n",
      "train loss 0.18871261\n",
      "train accuracy is 95.68%\n",
      "accuracy is 54.67%\n",
      "accuracy is 74.63%\n",
      "train loss 0.1606014\n",
      "train accuracy is 95.82%\n",
      "accuracy is 56.14%\n",
      "accuracy is 76.40%\n",
      "train loss 0.14145203\n",
      "train accuracy is 96.57%\n",
      "accuracy is 56.61%\n",
      "accuracy is 76.93%\n",
      "train loss 0.12705415\n",
      "train accuracy is 97.60%\n",
      "accuracy is 56.23%\n",
      "accuracy is 77.43%\n",
      "train loss 0.12089985\n",
      "train accuracy is 96.45%\n",
      "accuracy is 56.74%\n",
      "accuracy is 77.12%\n",
      "train loss 0.1157698\n",
      "train accuracy is 97.10%\n",
      "accuracy is 56.38%\n",
      "accuracy is 77.08%\n",
      "train loss 0.1226877\n",
      "train accuracy is 96.58%\n",
      "accuracy is 56.65%\n",
      "accuracy is 77.37%\n",
      "train loss 0.11799134\n",
      "train accuracy is 95.70%\n",
      "accuracy is 56.34%\n",
      "accuracy is 76.58%\n",
      "train loss 0.116106585\n",
      "train accuracy is 95.80%\n",
      "accuracy is 56.62%\n",
      "accuracy is 76.85%\n",
      "train loss 0.12206523\n",
      "train accuracy is 96.02%\n",
      "accuracy is 56.71%\n",
      "accuracy is 77.25%\n",
      "train loss 0.13072583\n",
      "train accuracy is 97.88%\n",
      "accuracy is 55.45%\n",
      "accuracy is 76.57%\n",
      "train loss 0.11904144\n",
      "train accuracy is 97.92%\n",
      "accuracy is 56.16%\n",
      "accuracy is 77.57%\n",
      "train loss 0.12553471\n"
     ]
    }
   ],
   "source": [
    "# 语义嵌入视觉(autoencoder)\n",
    "epochs = 2000\n",
    "s_input = 256\n",
    "v_input = 2048\n",
    "hid = 1024\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "\n",
    "    initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "\n",
    "    initial = tf.constant(0.05, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Placeholder\n",
    "# define placeholder for inputs to network\n",
    "v_features = tf.placeholder(tf.float32, [None, v_input])\n",
    "s_features = tf.placeholder(tf.float32, [None, s_input])\n",
    "\n",
    "# # Network\n",
    "# # encoder\n",
    "W_left_a1 = weight_variable([v_input, hid])\n",
    "b_left_a1 = bias_variable([hid])\n",
    "left_a1 = tf.nn.relu(tf.matmul(v_features, W_left_a1) + b_left_a1) # 2048*(2048,1024)-->1024\n",
    "\n",
    "\n",
    "W_left_a2 = weight_variable([hid, s_input])\n",
    "b_left_a2 = bias_variable([s_input])\n",
    "left_a2 = tf.nn.relu(tf.matmul(left_a1, W_left_a2) + b_left_a2) # 1024*(1024,256)-->256\n",
    "\n",
    "## decoder\n",
    "W_left_a3 = weight_variable([s_input, hid])\n",
    "b_left_a3 = bias_variable([hid])\n",
    "left_a3_z = tf.nn.relu(tf.matmul(left_a2, W_left_a3) + b_left_a3) # 256*(256,1024)-->1024\n",
    "left_a3_s = tf.nn.relu(tf.matmul(s_features, W_left_a3) + b_left_a3)  # 256*(256,1024)-->1024\n",
    "\n",
    "W_left_a4 = weight_variable([hid, v_input])\n",
    "b_left_a4 = bias_variable([v_input])\n",
    "left_a4_z = tf.nn.relu(tf.matmul(left_a3_z, W_left_a4) + b_left_a4) # 1024*(1024,2048)-->2048\n",
    "left_a4_s = tf.nn.relu(tf.matmul(left_a3_s, W_left_a4) + b_left_a4) # 1024*(1024,2048)-->2048\n",
    "\n",
    "# # loss\n",
    "\n",
    "# loss_1\n",
    "loss_1 = tf.losses.huber_loss(s_features,left_a2,delta=1.5)\n",
    "loss_1 = tf.reduce_sum(loss_1)\n",
    "# loss_2\n",
    "loss_2 = tf.losses.absolute_difference(v_features, left_a4_z)\n",
    "loss_2 = tf.reduce_sum(loss_2)\n",
    "# loss_3\n",
    "loss_3 = tf.losses.absolute_difference(v_features, left_a4_s)\n",
    "loss_3 = tf.reduce_sum(loss_3)\n",
    "# # loss_2\n",
    "# loss_2 = tf.losses.mean_squared_error(v_features, left_a4_z)\n",
    "# loss_2 = tf.reduce_sum(loss_2)\n",
    "# # loss_3\n",
    "# loss_3 = tf.losses.mean_squared_error(v_features, left_a4_s)\n",
    "# loss_3 = tf.reduce_sum(loss_3)\n",
    "\n",
    "\n",
    "# L2 regularisation for the fully connected parameters.\n",
    "\n",
    "regularisers_a = (tf.nn.l2_loss(W_left_a1) + tf.nn.l2_loss(b_left_a1)\n",
    "                  + tf.nn.l2_loss(W_left_a2) + tf.nn.l2_loss(b_left_a2)\n",
    "                 +tf.nn.l2_loss(W_left_a3) + tf.nn.l2_loss(b_left_a3)\n",
    "                  + tf.nn.l2_loss(W_left_a4) + tf.nn.l2_loss(b_left_a4))\n",
    "\n",
    "m=0.1\n",
    "n=0.3\n",
    "loss_sum = loss_1+m*loss_2+n*loss_3+1e-3 * regularisers_a\n",
    "\n",
    "#acc=  accuracy()\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss_sum)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# fig_loss = np.zeros([10])\n",
    "# fig_acc = np.zeros([10])\n",
    "#data_fit()\n",
    "\n",
    "#输出两个列表\n",
    "list_train = []\n",
    "list_3 = []\n",
    "list_4 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    s=[]\n",
    "    # Select a random batch of images\n",
    "    idx = np.random.randint(0, x_train_img.shape[0], 100)\n",
    "\n",
    "    v_feature = x_train_img[idx]\n",
    "    s = aux_data_train[idx]\n",
    "#     for i in range(len(idx)):\n",
    "\n",
    "#         if idx[i] <2000:\n",
    "#             s_attr = aux_data_train[0]\n",
    "#             s.append(s_attr)\n",
    "#         if 2000<= idx[i] < 4000:\n",
    "#             s_attr = aux_data_train[2000]\n",
    "#             s.append(s_attr)\n",
    "#         if 4000<= idx[i] < 6000:\n",
    "#             s_attr = aux_data_train[4000]\n",
    "#             s.append(s_attr)\n",
    "\n",
    "#     s_attr = np.atleast_2d(s_attr)\n",
    "\n",
    "    _, loss_val= sess.run([train_step, loss_sum], feed_dict={v_features: v_feature , s_features: s})\n",
    "    \n",
    "    if epoch%50==0:\n",
    "        print('train loss',loss_val)\n",
    "        s_train = np.array([aux_data_train[0],aux_data_train[samples_num],aux_data_train[2*samples_num]])\n",
    "        S_train= sess.run(left_a4_s, feed_dict={s_features: s_train})\n",
    "        \n",
    "        s_attr_2 = np.array([aux_data_test[0],aux_data_test[2000],aux_data_test[4000],aux_data_test[6000]])\n",
    "        S_attr_2= sess.run(left_a4_s, feed_dict={s_features: s_attr_2})\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 7种语义嵌入子空间\n",
    "#         s_attr_1 = np.array([aux_data_train[0],aux_data_train[samples_num],aux_data_train[2*samples_num]])\n",
    "#         S_attr_1= sess.run(left_a4_z, feed_dict={left_a2: s_attr_1})\n",
    "#         print(S_attr_1.shape)\n",
    "\n",
    "#         print(S_attr_2.shape)\n",
    "        count_train = calAccuracy_Euc(samples_num,x_train_img,S_train,class_num = 3)\n",
    "        count_1 = calAccuracy_Euc(2000,x_test_img,S_attr_2,class_num = 4)\n",
    "        count_2 = calAccuracy_Euc(2000,x_test_img[0:6000],S_attr_2[0:3],class_num = 3)\n",
    "        \n",
    "        list_train.append((100*count_train)/(samples_num*3))\n",
    "        list_3.append(100*count_2/6000)\n",
    "        list_4.append(100*count_1/8000)\n",
    "        print('train accuracy is %0.2f%%'%(100*count_train/(samples_num*3)))\n",
    "        print('accuracy is %0.2f%%'%(100*count_1/8000))\n",
    "        print('accuracy is %0.2f%%'%(100*count_2/6000))\n",
    "\n",
    "   # print('accuracy:',accuracy)\n",
    "#                 if epoch %1000 == 0:\n",
    "#                     acc= accuracy()\n",
    "#                     fig_loss[epoch//1000] = loss_val\n",
    "#                     fig_acc[epoch//1000] = acc\n",
    "\n",
    "\n",
    "# print(acc)                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[33.333333333333336, 55.21666666666667, 57.25, 59.63333333333333, 65.41666666666667, 72.6, 77.6, 76.6, 77.93333333333334, 74.98333333333333, 74.81666666666666, 75.81666666666666, 76.9, 77.08333333333333, 76.23333333333333, 75.45, 76.38333333333334, 76.48333333333333, 76.76666666666667, 75.91666666666667, 76.7, 77.95, 78.11666666666666, 76.38333333333334, 76.51666666666667, 77.6, 77.35, 74.1, 77.08333333333333, 77.4, 77.21666666666667, 77.81666666666666, 77.05, 76.25, 78.11666666666666, 76.66666666666667, 76.18333333333334, 75.73333333333333, 77.46666666666667, 76.96666666666667]\n",
      "[25.0, 40.6, 42.0875, 43.4625, 47.275, 52.675, 55.825, 56.0375, 56.5125, 55.1, 54.9, 55.65, 55.8625, 56.35, 55.275, 55.825, 56.3, 55.4375, 55.025, 55.8, 55.5625, 55.525, 56.15, 53.8625, 55.975, 55.8875, 55.9, 55.05, 56.725, 56.375, 56.675, 55.825, 55.9375, 54.9625, 55.175, 55.1875, 55.5125, 56.25, 56.5, 56.025]\n"
     ]
    }
   ],
   "source": [
    "print(len(list_train))\n",
    "print(list_3)\n",
    "print(list_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.98333333333333\n"
     ]
    }
   ],
   "source": [
    "tmp = [ 53.8125, 55.8125, 54.3, 56.3875, 55.7875, 56.125, 55.925, 54.9125, 56.575, 56.1, 56.3625, 56.825, 56.45, 55.7, 56.2, 54.9125, 56.6875, 56.075, 56.775, 56.3125, 55.8875, 56.0375, 56.3, 55.7625, 56.425, 56.9125, 56.125, 56.575, 56.5625, 56.3, 56.325, 53.875, 56.55, 56.2375, 57.05, 56.125, 54.4625, 54.9875, 56.5, 56.7375, 55.9125, 55.4125, 56.425, 55.875, 54.025, 56.5125, 57.0, 56.2625]\n",
    "print(np.mean(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nA77I41S8z8eJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "accs =list_train\n",
    "\n",
    "\n",
    "val_accs = list_3\n",
    "\n",
    "\n",
    "val_accs2 = list_4\n",
    "\n",
    "epochs = len(accs)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, metrics in enumerate(zip([accs], [val_accs], [val_accs2], ['Accuracy'])):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[3]))\n",
    "    plt.plot(range(epochs), metrics[1], label='Testing A4 {}'.format(metrics[3]))\n",
    "    plt.plot(range(epochs), metrics[2], label='Testing B4 {}'.format(metrics[3]))\n",
    "    plt.legend()\n",
    "    \n",
    "def to_percent(temp, position):\n",
    "    return '%1.0f'%(100*temp)\n",
    "# plt.gca().yaxis.set_major_formatter(FuncFormatter(to_percent))\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(to_percent))\n",
    "\n",
    "# plt.savefig(\"acc.png\")\n",
    "plt.savefig(\"FE_Task_A4.png\",dpi=700,bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7种语义嵌入子空间\n",
    "s_attr_1 = np.array([aux_data_train[0],aux_data_train[2000],aux_data_train[4000]])\n",
    "S_attr_1= sess.run(left_a2, feed_dict={att_features: s_attr_1})\n",
    "print(S_attr_1.shape)\n",
    "\n",
    "s_attr_2 = np.array([aux_data_test[0],aux_data_test[2000],aux_data_test[4000],aux_data_test[6000]])\n",
    "S_attr_2= sess.run(left_a2, feed_dict={att_features: s_attr_2})\n",
    "print(S_attr_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算训练集精确度\n",
    "count = calAccuracy_Euc(x_train_img,S_attr_1)\n",
    "print('accuracy is %0.2f%%'%(100*count/6000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算测试集精确度-4class\n",
    "count = calAccuracy_Euc(x_test_img,S_attr_2,class_num = 4)\n",
    "print('accuracy is %0.2f%%'%(100*count/8000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算测试集精确度-3class\n",
    "count = calAccuracy_Euc(x_test_img[0:6000],S_attr_2[0:3],class_num = 3)\n",
    "print('accuracy is %0.2f%%'%(100*count/6000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 语义嵌入视觉(autoencoder)\n",
    "# epochs = 10000\n",
    "# att_input = 1000\n",
    "# img_input = 2048\n",
    "# att_hid = 1350\n",
    "\n",
    "\n",
    "# def weight_variable(shape):\n",
    "\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# def bias_variable(shape):\n",
    "\n",
    "#     initial = tf.constant(0.05, shape=shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Placeholder\n",
    "# # define placeholder for inputs to network\n",
    "# att_features = tf.placeholder(tf.float32, [None, att_input])\n",
    "# #att_features = tf.placeholder(tf.float32, [None, 512])\n",
    "# visual_features = tf.placeholder(tf.float32, [None, img_input])\n",
    "\n",
    "# # # Network\n",
    "\n",
    "# # # encoder\n",
    "# W_left_a1 = weight_variable([att_input, att_hid])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_a1 = bias_variable([att_hid])\n",
    "# left_a1 = tf.nn.relu(tf.matmul(att_features, W_left_a1) + b_left_a1)\n",
    "\n",
    "\n",
    "# W_left_a2 = weight_variable([att_hid, img_input])\n",
    "# b_left_a2 = bias_variable([img_input])\n",
    "# left_a2 = tf.nn.relu(tf.matmul(left_a1, W_left_a2) + b_left_a2)\n",
    "\n",
    "# ## decoder\n",
    "# W_left_a3 = weight_variable([img_input, att_hid])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_a3 = bias_variable([att_hid])\n",
    "# left_a3_att = tf.nn.relu(tf.matmul(left_a2, W_left_a3) + b_left_a3)\n",
    "# left_a3_img = tf.nn.relu(tf.matmul(visual_features, W_left_a3) + b_left_a3)\n",
    "\n",
    "# W_left_a4 = weight_variable([att_hid, att_input])\n",
    "# b_left_a4 = bias_variable([att_input])\n",
    "# left_a4_att = tf.nn.relu(tf.matmul(left_a3_att, W_left_a4) + b_left_a4)\n",
    "# left_a4_img = tf.nn.relu(tf.matmul(left_a3_img, W_left_a4) + b_left_a4)\n",
    "\n",
    "# # # loss\n",
    "# loss_a = tf.losses.huber_loss(visual_features,left_a2)\n",
    "# # loss_a = wasserstein_loss(visual_features,left_a2 )\n",
    "# # loss_b = tf.losses.mean_squared_error(att_features, left_a4)\n",
    "# loss_b = tf.losses.mean_squared_error(att_features, left_a4_att)\n",
    "# loss_c = tf.losses.mean_squared_error(att_features, left_a4_img)\n",
    "# # L2 regularisation for the fully connected parameters.\n",
    "\n",
    "# regularisers_a = (tf.nn.l2_loss(W_left_a1) + tf.nn.l2_loss(b_left_a1)\n",
    "#                   + tf.nn.l2_loss(W_left_a2) + tf.nn.l2_loss(b_left_a2)\n",
    "#                  +tf.nn.l2_loss(W_left_a3) + tf.nn.l2_loss(b_left_a3)\n",
    "#                   + tf.nn.l2_loss(W_left_a4) + tf.nn.l2_loss(b_left_a4))\n",
    "\n",
    "# k = 0.9\n",
    "# loss_sum = loss_a+k*loss_b+k*loss_c+1e-3 * regularisers_a\n",
    "\n",
    "\n",
    "\n",
    "# #acc=  accuracy()\n",
    "\n",
    "# train_step = tf.train.AdamOptimizer(0.0005).minimize(loss_sum)\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# # fig_loss = np.zeros([10])\n",
    "# # fig_acc = np.zeros([10])\n",
    "# #data_fit()\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "\n",
    "#     s=[]\n",
    "#     # Select a random batch of images\n",
    "#     idx = np.random.randint(0, x_train_img.shape[0], 100)\n",
    "\n",
    "#     v_feature = x_train_img[idx]\n",
    "#     s = aux_data_train[idx]\n",
    "# #     for i in range(len(idx)):\n",
    "\n",
    "# #         if idx[i] <2000:\n",
    "# #             s_attr = aux_data_train[0]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 2000<= idx[i] < 4000:\n",
    "# #             s_attr = aux_data_train[2000]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 4000<= idx[i] < 6000:\n",
    "# #             s_attr = aux_data_train[4000]\n",
    "# #             s.append(s_attr)\n",
    "\n",
    "# #     s_attr = np.atleast_2d(s_attr)\n",
    "\n",
    "#     _, loss_val= sess.run([train_step, loss_sum], feed_dict={visual_features: v_feature , att_features: s})\n",
    "    \n",
    "#     if epoch%100==0:\n",
    "#         print('train loss',loss_val)\n",
    "#         # 7种语义嵌入子空间\n",
    "#         s_attr_1 = np.array([aux_data_train[0],aux_data_train[2000],aux_data_train[4000]])\n",
    "#         S_attr_1= sess.run(left_a2, feed_dict={att_features: s_attr_1})\n",
    "# #         print(S_attr_1.shape)\n",
    "#         s_attr_2 = np.array([aux_data_test[0],aux_data_test[2000],aux_data_test[4000],aux_data_test[6000]])\n",
    "#         S_attr_2= sess.run(left_a2, feed_dict={att_features: s_attr_2})\n",
    "# #         print(S_attr_2.shape)\n",
    "#         count_1 = calAccuracy_Euc(x_test_img,S_attr_2,class_num = 4)\n",
    "#         count_2 = calAccuracy_Euc(x_test_img[0:6000],S_attr_2[0:3],class_num = 3)\n",
    "#         print('accuracy is %0.2f%%'%(100*count_1/8000))     \n",
    "#         print('accuracy is %0.2f%%'%(100*count_2/6000))  \n",
    "\n",
    "#    # print('accuracy:',accuracy)\n",
    "# #                 if epoch %1000 == 0:\n",
    "# #                     acc= accuracy()\n",
    "# #                     fig_loss[epoch//1000] = loss_val\n",
    "# #                     fig_acc[epoch//1000] = acc\n",
    "\n",
    "\n",
    "# # print(acc)                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 语义嵌入视觉(vae)\n",
    "# epochs = 10000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def weight_variable(shape):\n",
    "\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "# def bias_variable(shape):\n",
    "\n",
    "#     initial = tf.constant(0.05, shape=shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Placeholder\n",
    "# # define placeholder for inputs to network\n",
    "# att_features = tf.placeholder(tf.float32, [None, 1000])\n",
    "# #att_features = tf.placeholder(tf.float32, [None, 512])\n",
    "# visual_features = tf.placeholder(tf.float32, [None, 2048])\n",
    "\n",
    "# # # Network\n",
    "\n",
    "# # # encoder\n",
    "# W_left_a1 = weight_variable([1000, 1560])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_a1 = bias_variable([1560])\n",
    "# left_a1 = tf.nn.relu(tf.matmul(att_features, W_left_a1) + b_left_a1)\n",
    "\n",
    "\n",
    "# W_left_a2_mean = weight_variable([1560, 2048])\n",
    "# b_left_a2_mean = bias_variable([2048])\n",
    "# left_a2_mean = tf.nn.relu(tf.matmul(left_a1, W_left_a2_mean) + b_left_a2_mean)\n",
    "\n",
    "# W_left_a2_var = weight_variable([1560, 2048])\n",
    "# b_left_a2_var = bias_variable([2048])\n",
    "# left_a2_var = tf.nn.relu(tf.matmul(left_a1, W_left_a2_var) + b_left_a2_var)\n",
    "\n",
    "# # 重参数技巧\n",
    "# def sampling(args):\n",
    "#     z_mean, z_log_var = args\n",
    "#     epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "#     return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# # 重参数层，相当于给输入加入噪声\n",
    "# z = Lambda(sampling, output_shape=(2048,))([left_a2_mean, left_a2_var])\n",
    "\n",
    "# ## decoder\n",
    "# W_left_a3 = weight_variable([2048, 1560])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_a3 = bias_variable([1560])\n",
    "# left_a3 = tf.nn.relu(tf.matmul(z, W_left_a3) + b_left_a3)\n",
    "\n",
    "\n",
    "# W_left_a4 = weight_variable([1560, 1000])\n",
    "# b_left_a4 = bias_variable([1000])\n",
    "# left_a4 = tf.nn.relu(tf.matmul(left_a3, W_left_a4) + b_left_a4)\n",
    "\n",
    "# # # # loss\n",
    "\n",
    "# loss_a = tf.losses.mean_squared_error(z, visual_features) \n",
    "# loss_b = tf.losses.mean_squared_error(att_features, left_a4)\n",
    "\n",
    "# # marginal_likelihood loss为y与输入数据x之间交叉墒，即解码器的损失\n",
    "# # marginal_likelihood = tf.reduce_sum(att_features * tf.log(left_a4) + (1 - att_features) * tf.log(1 - left_a4), 1)\n",
    "# # marginal_likelihood = tf.losses.mean_squared_error(att_features, left_a4)\n",
    "\n",
    "# # # KL_divergence为z与标准高斯分布之间的差距，即编码器的损失\n",
    "# # KL_divergence = 0.5 * tf.reduce_sum(tf.square(left_a2_mean) + tf.square(left_a2_var) - tf.log(1e-8 + tf.square(left_a2_var)) - 1, 1)\n",
    "# # KL_divergence = tf.reduce_mean(KL_divergence)\n",
    "\n",
    "# # # 变分下界L(x)，目标最大化\n",
    "# # ELBO = marginal_likelihood - KL_divergence\n",
    "\n",
    "# # # 令损失函数为-L(x)，目标梯度下降最小化\n",
    "# # loss_b = -ELBO\n",
    "\n",
    "# # L2 regularisation for the fully connected parameters.\n",
    "\n",
    "# regularisers_a = (tf.nn.l2_loss(W_left_a1) + tf.nn.l2_loss(b_left_a1)+ tf.nn.l2_loss(W_left_a2_mean) + tf.nn.l2_loss(b_left_a2_var)\n",
    "#                   +tf.nn.l2_loss(W_left_a2_var) + tf.nn.l2_loss(b_left_a2_var)\n",
    "#                  +tf.nn.l2_loss(W_left_a3) + tf.nn.l2_loss(b_left_a3)+ tf.nn.l2_loss(W_left_a4) + tf.nn.l2_loss(b_left_a4))\n",
    "\n",
    "\n",
    "# # loss_a = loss_a+0.5*loss_b+1e-3 * regularisers_a\n",
    "# loss_sum = loss_a+0.5*loss_b+1e-3 * regularisers_a\n",
    "\n",
    "\n",
    "\n",
    "# #acc=  accuracy()\n",
    "\n",
    "# train_step = tf.train.AdamOptimizer(0.001).minimize(loss_sum)\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# fig_loss = np.zeros([10])\n",
    "# fig_acc = np.zeros([10])\n",
    "# #data_fit()\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "\n",
    "#     s=[]\n",
    "#     # Select a random batch of images\n",
    "#     idx = np.random.randint(0, x_train_img.shape[0], 100)\n",
    "\n",
    "#     v_feature = x_train_img[idx]\n",
    "#     s = aux_data_train[idx]\n",
    "# #     for i in range(len(idx)):\n",
    "\n",
    "# #         if idx[i] <2000:\n",
    "# #             s_attr = aux_data_train[0]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 2000<= idx[i] < 4000:\n",
    "# #             s_attr = aux_data_train[2000]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 4000<= idx[i] < 6000:\n",
    "# #             s_attr = aux_data_train[4000]\n",
    "# #             s.append(s_attr)\n",
    "\n",
    "# #     s_attr = np.atleast_2d(s_attr)\n",
    "\n",
    "#     _, loss_val= sess.run([train_step, loss_a], feed_dict={visual_features: v_feature , att_features: s})\n",
    "    \n",
    "#     if epoch%100==0:\n",
    "#         print('train loss',loss_val)\n",
    "\n",
    "#    # print('accuracy:',accuracy)\n",
    "# #                 if epoch %1000 == 0:\n",
    "# #                     acc= accuracy()\n",
    "# #                     fig_loss[epoch//1000] = loss_val\n",
    "# #                     fig_acc[epoch//1000] = acc\n",
    "\n",
    "\n",
    "# # print(acc)                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 设置超参数\n",
    "# batch_size = 100\n",
    "# original_dim_img = 2048\n",
    "# original_dim_att = 1000\n",
    "# latent_dim = 2048 # 隐变量取2维只是为了方便后面画图\n",
    "# intermediate_dim = 1560\n",
    "# epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_img = Input(shape=(original_dim_img,))\n",
    "# x_att = Input(shape=(original_dim_att,))\n",
    "# h_att = Dense(intermediate_dim, activation='relu')(x_att)\n",
    "\n",
    "# # 算p(Z|X)的均值和方差\n",
    "# z_mean = Dense(latent_dim)(h_att)\n",
    "# z_log_var = Dense(latent_dim)(h_att)\n",
    "\n",
    "# # 重参数技巧\n",
    "# def sampling(args):\n",
    "#     z_mean, z_log_var = args\n",
    "#     epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "#     return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# # 重参数层，相当于给输入加入噪声\n",
    "# z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# # 解码层，也就是生成器部分\n",
    "# decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "# decoder_mean = Dense(original_dim_att, activation='sigmoid')\n",
    "# h_decoded = decoder_h(z)\n",
    "# x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# # 建立模型\n",
    "# model = Model([x_img,x_att], x_decoded_mean)\n",
    "\n",
    "# # xent_loss是重构loss，kl_loss是KL loss\n",
    "# xent_loss = K.sum(K.binary_crossentropy(x_att, x_decoded_mean), axis=-1)\n",
    "# kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "# vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "# # 对齐loss\n",
    "# align_loss = 0.5*tf.losses.mean_squared_error(z, x_img) \n",
    "\n",
    "# # loss_sum = vae_loss + 0.5*align_loss\n",
    "\n",
    "# # add_loss是新增的方法，用于更灵活地添加各种loss\n",
    "# loss_sum = model.add_loss(vae_loss)\n",
    "# loss_sum = model.add_loss(align_loss)\n",
    "\n",
    "# opt = keras.optimizers.adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "# model.compile(optimizer=opt,metrics=[vae_loss, align_loss])\n",
    "# model.summary()\n",
    "\n",
    "# model.fit([x_train_img,aux_data_train],\n",
    "#         shuffle=True,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 7种语义嵌入子空间\n",
    "# s_attr_1 = np.array([aux_data_train[0],aux_data_train[2000],aux_data_train[4000]])\n",
    "# #取某一层的输出为输出新建为model，采用函数模型\n",
    "# z_layer_model = Model(inputs=x_att,outputs=model.get_layer('lambda_11').output)\n",
    "# #以这个model的预测值作为输出\n",
    "# S_attr_1 = z_layer_model.predict(s_attr_1)\n",
    "# print(S_attr_1.shape)\n",
    "\n",
    "# s_attr_2 = np.array([aux_data_test[0],aux_data_test[2000],aux_data_test[4000],aux_data_test[6000]])\n",
    "# #取某一层的输出为输出新建为model，采用函数模型\n",
    "# # z_layer_model = Model(inputs=model.input,outputs=model.get_layer('lambda_2').output)\n",
    "# #以这个model的预测值作为输出\n",
    "# S_attr_2 = z_layer_model.predict(s_attr_2)\n",
    "# print(S_attr_2.shape)\n",
    "\n",
    "# # 计算欧氏距离\n",
    "# def dist(x,y):\n",
    "#     return np.sqrt(np.sum(np.square(x-y)))\n",
    "\n",
    "# # 按欧式距离计算精确度\n",
    "# def calAccuracy_Euc(latent_x,latent_c,class_num = 3):\n",
    "#     predict_list = []\n",
    "# #     latent_x = latent_x.tolist()\n",
    "# #     latent_c = latent_c.tolist()\n",
    "    \n",
    "#     if class_num == 3:\n",
    "#         for i in range(6000): \n",
    "#             distance_list = [dist(latent_x[i], latent_c[0]),\n",
    "#                              dist(latent_x[i], latent_c[1]),\n",
    "#                              dist(latent_x[i], latent_c[2])]\n",
    "#             min_index = distance_list.index(min(distance_list))\n",
    "#             predict_list.append(min_index)\n",
    "        \n",
    "#         print(predict_list)\n",
    "\n",
    "#         count = 0\n",
    "#         for i in range(0,2000):\n",
    "#             if predict_list[i]==0:\n",
    "#                 count=count+1\n",
    "#         for i in range(2000,4000):\n",
    "#             if predict_list[i]==1:\n",
    "#                 count=count+1\n",
    "#         for i in range(4000,6000):\n",
    "#             if predict_list[i]==2:\n",
    "#                 count=count+1\n",
    "\n",
    "#         return count\n",
    "    \n",
    "#     if class_num == 4:\n",
    "#         for i in range(8000):\n",
    "#             distance_list = [dist(latent_x[i], latent_c[0]),\n",
    "#                              dist(latent_x[i], latent_c[1]),\n",
    "#                              dist(latent_x[i], latent_c[2]),\n",
    "#                              dist(latent_x[i], latent_c[3])]\n",
    "#             min_index = distance_list.index(min(distance_list))\n",
    "#             predict_list.append(min_index)\n",
    "        \n",
    "#         print(predict_list)\n",
    "\n",
    "#         count = 0\n",
    "#         for i in range(0,2000):\n",
    "#             if predict_list[i]==0:\n",
    "#                 count=count+1\n",
    "#         for i in range(2000,4000):\n",
    "#             if predict_list[i]==1:\n",
    "#                 count=count+1\n",
    "#         for i in range(4000,6000):\n",
    "#             if predict_list[i]==2:\n",
    "#                 count=count+1\n",
    "#         for i in range(6000,8000):\n",
    "#             if predict_list[i]==3:\n",
    "#                 count=count+1\n",
    "#         return count\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 语义嵌入视觉\n",
    "# epochs = 10000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def weight_variable(shape):\n",
    "\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "# def bias_variable(shape):\n",
    "\n",
    "#     initial = tf.constant(0.05, shape=shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Placeholder\n",
    "# # define placeholder for inputs to network\n",
    "# att_features = tf.placeholder(tf.float32, [None, 1000])\n",
    "# #att_features = tf.placeholder(tf.float32, [None, 512])\n",
    "# visual_features = tf.placeholder(tf.float32, [None, 2048])\n",
    "\n",
    "# # # Network\n",
    "\n",
    "\n",
    "# W_left_a1 = weight_variable([1000, 1024])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_a1 = bias_variable([1024])\n",
    "# left_a1 = tf.nn.relu(tf.matmul(att_features, W_left_a1) + b_left_a1)\n",
    "\n",
    "\n",
    "# W_left_a2 = weight_variable([1024, 2048])\n",
    "# b_left_a2 = bias_variable([2048])\n",
    "# left_a2 = tf.nn.relu(tf.matmul(left_a1, W_left_a2) + b_left_a2)\n",
    "\n",
    "# # # loss\n",
    "\n",
    "# loss_a = tf.reduce_mean(tf.square(left_a2 - visual_features))    \n",
    "\n",
    "# # L2 regularisation for the fully connected parameters.\n",
    "\n",
    "# regularisers_a = (tf.nn.l2_loss(W_left_a1) + tf.nn.l2_loss(b_left_a1)\n",
    "#                     + tf.nn.l2_loss(W_left_a2) + tf.nn.l2_loss(b_left_a2))\n",
    "\n",
    "\n",
    "# loss_a += 1e-3 * regularisers_a\n",
    "\n",
    "\n",
    "\n",
    "# #acc=  accuracy()\n",
    "\n",
    "# train_step = tf.train.AdamOptimizer(0.0001).minimize(loss_a)\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# fig_loss = np.zeros([10])\n",
    "# fig_acc = np.zeros([10])\n",
    "# #data_fit()\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "\n",
    "#     s=[]\n",
    "#     # Select a random batch of images\n",
    "#     idx = np.random.randint(0, x_train_img.shape[0], 100)\n",
    "\n",
    "#     v_feature = x_train_img[idx]\n",
    "#     s = aux_data_train[idx]\n",
    "# #     for i in range(len(idx)):\n",
    "\n",
    "# #         if idx[i] <2000:\n",
    "# #             s_attr = aux_data_train[0]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 2000<= idx[i] < 4000:\n",
    "# #             s_attr = aux_data_train[2000]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 4000<= idx[i] < 6000:\n",
    "# #             s_attr = aux_data_train[4000]\n",
    "# #             s.append(s_attr)\n",
    "\n",
    "# #     s_attr = np.atleast_2d(s_attr)\n",
    "\n",
    "#     _, loss_val= sess.run([train_step, loss_a], feed_dict={visual_features: v_feature , att_features: s})\n",
    "    \n",
    "#     if epoch%100==0:\n",
    "#         print('train loss',loss_val)\n",
    "\n",
    "#    # print('accuracy:',accuracy)\n",
    "# #                 if epoch %1000 == 0:\n",
    "# #                     acc= accuracy()\n",
    "# #                     fig_loss[epoch//1000] = loss_val\n",
    "# #                     fig_acc[epoch//1000] = acc\n",
    "\n",
    "\n",
    "# # print(acc)                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 语义与视觉嵌入公共子空间\n",
    "# epochs = 10000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def weight_variable(shape):\n",
    "\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "# def bias_variable(shape):\n",
    "\n",
    "#     initial = tf.constant(0.05, shape=shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Placeholder\n",
    "# # define placeholder for inputs to network\n",
    "# att_features = tf.placeholder(tf.float32, [None, 1000])\n",
    "# #att_features = tf.placeholder(tf.float32, [None, 512])\n",
    "# visual_features = tf.placeholder(tf.float32, [None, 512])\n",
    "\n",
    "# # # Network\n",
    "\n",
    "\n",
    "# W_left_a1 = weight_variable([1000, 1024])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_a1 = bias_variable([1024])\n",
    "# left_a1 = tf.nn.relu(tf.matmul(att_features, W_left_a1) + b_left_a1)\n",
    "\n",
    "\n",
    "# W_left_a2 = weight_variable([1024, 2048])\n",
    "# b_left_a2 = bias_variable([2048])\n",
    "# left_a2 = tf.nn.relu(tf.matmul(left_a1, W_left_a2) + b_left_a2)\n",
    "\n",
    "# W_left_b1 = weight_variable([512, 1024])\n",
    "# #W_left_a1 = weight_variable([512, 1024])\n",
    "# b_left_b1 = bias_variable([1024])\n",
    "# left_b1 = tf.nn.relu(tf.matmul(visual_features, W_left_b1) + b_left_b1)\n",
    "\n",
    "\n",
    "# W_left_b2 = weight_variable([1024, 2048])\n",
    "# b_left_b2 = bias_variable([2048])\n",
    "# left_b2 = tf.nn.relu(tf.matmul(left_b1, W_left_b2) + b_left_b2)\n",
    "\n",
    "\n",
    "\n",
    "# # # loss\n",
    "\n",
    "# loss_a = tf.reduce_mean(tf.square(left_a2 - left_b2))    \n",
    "\n",
    "# # L2 regularisation for the fully connected parameters.\n",
    "\n",
    "# regularisers_a = (tf.nn.l2_loss(W_left_a1) + tf.nn.l2_loss(b_left_a1)+ tf.nn.l2_loss(W_left_a2) + tf.nn.l2_loss(b_left_a2)\n",
    "#                  +tf.nn.l2_loss(W_left_b1) + tf.nn.l2_loss(b_left_b1)+ tf.nn.l2_loss(W_left_b2) + tf.nn.l2_loss(b_left_b2))\n",
    "\n",
    "\n",
    "# loss_a += 1e-3 * regularisers_a\n",
    "\n",
    "\n",
    "\n",
    "# #acc=  accuracy()\n",
    "\n",
    "# train_step = tf.train.AdamOptimizer(0.0001).minimize(loss_a)\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# fig_loss = np.zeros([10])\n",
    "# fig_acc = np.zeros([10])\n",
    "# #data_fit()\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "\n",
    "#     s=[]\n",
    "#     # Select a random batch of images\n",
    "#     idx = np.random.randint(0, x_train_img.shape[0], 100)\n",
    "\n",
    "#     v_feature = x_train_img[idx]\n",
    "#     s = aux_data_train[idx]\n",
    "# #     for i in range(len(idx)):\n",
    "\n",
    "# #         if idx[i] <2000:\n",
    "# #             s_attr = aux_data_train[0]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 2000<= idx[i] < 4000:\n",
    "# #             s_attr = aux_data_train[2000]\n",
    "# #             s.append(s_attr)\n",
    "# #         if 4000<= idx[i] < 6000:\n",
    "# #             s_attr = aux_data_train[4000]\n",
    "# #             s.append(s_attr)\n",
    "\n",
    "# #     s_attr = np.atleast_2d(s_attr)\n",
    "\n",
    "#     _, loss_val= sess.run([train_step, loss_a], feed_dict={visual_features: v_feature , att_features: s})\n",
    "    \n",
    "#     if epoch%100==0:\n",
    "#         print('train loss',loss_val)\n",
    "\n",
    "#    # print('accuracy:',accuracy)\n",
    "# #                 if epoch %1000 == 0:\n",
    "# #                     acc= accuracy()\n",
    "# #                     fig_loss[epoch//1000] = loss_val\n",
    "# #                     fig_acc[epoch//1000] = acc\n",
    "\n",
    "\n",
    "# # print(acc)                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 按余弦相似度分类\n",
    "# def cosine_classify(_latent_visual,_latent_semantic):\n",
    "#     predict_list = []\n",
    "#     latent_visual = _latent_visual.tolist()\n",
    "#     latent_semantic = _latent_semantic.tolist()\n",
    "#     if _latent_semantic.shape[0] == 3:\n",
    "#         for i in range(len(latent_visual)):\n",
    "#             cosine_list = [cosine_similarity(latent_visual[i], latent_semantic[0]),\n",
    "#                            cosine_similarity(latent_visual[i], latent_semantic[1]),\n",
    "#                            cosine_similarity(latent_visual[i], latent_semantic[2]),\n",
    "#     #                        cosine_similarity(latent_visual[i], latent_semantic[3])\n",
    "#                           ]\n",
    "#             max_index = cosine_list.index(max(cosine_list))\n",
    "#             predict_list.append(max_index)\n",
    "#     else:\n",
    "#         for i in range(len(latent_visual)):\n",
    "#             cosine_list = [cosine_similarity(latent_visual[i], latent_semantic[0]),\n",
    "#                            cosine_similarity(latent_visual[i], latent_semantic[1]),\n",
    "#                            cosine_similarity(latent_visual[i], latent_semantic[2]),\n",
    "#                            cosine_similarity(latent_visual[i], latent_semantic[3])\n",
    "#                           ]\n",
    "#             max_index = cosine_list.index(max(cosine_list))\n",
    "#             predict_list.append(max_index)\n",
    "            \n",
    "#     return predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算精确度\n",
    "# def calAccuracy(latent_x,latent_c):\n",
    "    \n",
    "#     predict_list = cosine_classify(latent_x,latent_c)\n",
    "    \n",
    "#     print(predict_list)\n",
    "\n",
    "#     count = 0\n",
    "#     for i in range(0,2000):\n",
    "#         if predict_list[i]==0:\n",
    "#             count=count+1\n",
    "#     for i in range(2000,4000):\n",
    "#         if predict_list[i]==1:\n",
    "#             count=count+1\n",
    "#     for i in range(4000,6000):\n",
    "#         if predict_list[i]==2:\n",
    "#             count=count+1\n",
    "#     if len(predict_list)>6000:\n",
    "#         for i in range(6000,8000):\n",
    "#             if predict_list[i]==3:\n",
    "#                 count=count+1\n",
    "            \n",
    "\n",
    "#     return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算欧氏距离\n",
    "# def calEuclideanDistance(vec1,vec2):  \n",
    "#     dist = np.sqrt(np.sum(np.square(vec1 - vec2)))  \n",
    "#     return dist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 视觉向量嵌入子空间\n",
    "# V_img_1= sess.run(left_b2, feed_dict={visual_features: x_train_img})\n",
    "# print(V_img_1.shape)\n",
    "\n",
    "\n",
    "# V_img_2= sess.run(left_b2, feed_dict={visual_features: x_test_img})\n",
    "# print(V_img_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-115]",
   "language": "python",
   "name": "conda-env-tensorflow-115-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
